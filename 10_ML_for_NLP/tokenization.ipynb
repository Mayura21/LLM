{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toeknization and Basic Terminologies\n",
    "1. Corpus - Paragraph\n",
    "2. Documents - Sentences\n",
    "3. Vocabulary - Unique words present in paragraph\n",
    "4. Words - Words in corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization  \n",
    "Corpus - My name is Raj. I have a interest in ML, DL, NN. I am also a student.\n",
    "Tokens are sentences. \n",
    "\n",
    "1. My name is Raj and I am learning ML, DL and NN.\n",
    "2. I am also a student.\n",
    "\n",
    "\n",
    "Toeknization to word\n",
    "\n",
    "I like to drink Apple juice. My friend likes Mango juice.\n",
    "Tokenization => Tokens (sentences)\n",
    " - I like to drink Apple juice.\n",
    " - My friend likes Mango juice.\n",
    "\n",
    "Total 11 words\n",
    "Unique words\n",
    "[I, like, to, drink, Apple, juice, My, friend, likes, Mango]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
